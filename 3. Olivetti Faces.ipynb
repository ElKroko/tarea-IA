{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 3: Olivetti Faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tSeguirá trabajando con el dataset: Olivetti Faces. Como primer paso usted deberá cargar los datos y corroborar las dimensiones del dataset, el cual debe ser 400 x 4096\n",
    "\n",
    "2. Sabiendo que el número de clusters (personas) es 40, aplique K-Means y cluster jerárquico. Mediante el método del codo, identifique cuántos clusters le entrega cada uno de los algoritmos. ¿Cuál le da mejor resultado?\n",
    "\n",
    "3. Ahora aplique PCA al dataset. Quédese con un número de componentes principales tal que pueda capturar el 90% de la varianza explicada . ¿Cuántos componentes principales son?\n",
    "\n",
    "4. Aplique K-Means y cluster jerárquico al dataset reducido por PCA. Mediante el método del codo, identifique cuántos clusters le entrega cada uno de los algoritmos. ¿Cuál algoritmo le da mejor resultado? Compare los resultados con y sin PCA. ¿Sirvió de algo aplicar PCA?\n",
    "\n",
    "5. Divida el dataset en training y testing set. 80% training y 20% test. Use el coeficiente de Silhouette para estimar los valores de los parámetros de DBSCAN aplicado al training set.\n",
    "\n",
    "6. Con los valores estimados, aplique DBSCAN al training set y luego haga predicciones al testing set. Compare que tan bien estimo las etiquetas el algoritmo con respecto a las verdaderas etiquetas del testing set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Considerando lo aprendido en este módulo, implemente lo que Ud. crea necesario para mejorar los resultados del problema de decoding visto en clases \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming your dataset is stored in a DataFrame named 'df'\n",
    "# Separate the dependent variable 'Status' from the independent variables 'X'\n",
    "X = df_lexp.drop(columns=['Enc_status'])\n",
    "Y = df_lexp['Enc_status']\n",
    "\n",
    "# Impute missing values\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_imputed)\n",
    "\n",
    "# Apply PCA to reduce the data to 2 components\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Create a DataFrame with the PCA results and add the 'Status' column\n",
    "pca_df = pd.DataFrame(data=X_pca, columns=['PC1', 'PC2'])\n",
    "pca_df['Enc_status'] = Y\n",
    "\n",
    "# Visualize the data in a scatter plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x='PC1', y='PC2', hue='Enc_status', data=pca_df, palette='viridis', alpha=0.7)\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('PCA Visualization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Split the PCA-transformed data into training and testing sets\n",
    "X_train_pca, X_test_pca, Y_train_pca, Y_test_pca = train_test_split(X_pca, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the KNN classifier\n",
    "k = 5  # Number of neighbors to consider (can be adjusted)\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "# Train the model on the training data\n",
    "knn_classifier.fit(X_train_pca, Y_train_pca)\n",
    "\n",
    "# Predict 'Status' on the test set\n",
    "Y_pred_pca = knn_classifier.predict(X_test_pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Combine the PCA-transformed data and predicted class labels\n",
    "pca_result_df = pd.DataFrame(data=X_test_pca, columns=['PC1', 'PC2'])\n",
    "pca_result_df['Predicted_Status'] = Y_pred_pca\n",
    "\n",
    "# Visualize the data in a scatter plot with the predicted classes\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x='PC1', y='PC2', hue='Predicted_Status', data=pca_result_df, palette='viridis', alpha=0.7)\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('KNN Classification with PCA')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
